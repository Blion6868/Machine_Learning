{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "    \n",
    "    return str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\Anaconda3\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_core_web_sm' (2.2.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.1). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm',disable=['parser','tagger','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 11198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_punc(doc_text):\n",
    "    return[token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_file(r'C:\\Users\\bryan\\Desktop\\Computer Stuff\\tensor_flow_class\\TF_2_Notebooks_and_Data\\06-NLP-and-Text-Data\\melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter',\n",
       " '1',\n",
       " 'loomings',\n",
       " 'call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long',\n",
       " 'precisely',\n",
       " 'having',\n",
       " 'little',\n",
       " 'or',\n",
       " 'no',\n",
       " 'money',\n",
       " 'in',\n",
       " 'my',\n",
       " 'purse',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'particular',\n",
       " 'to',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'on',\n",
       " 'shore',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'i',\n",
       " 'would',\n",
       " 'sail',\n",
       " 'about',\n",
       " 'a',\n",
       " 'little',\n",
       " 'and',\n",
       " 'see',\n",
       " 'the',\n",
       " 'watery',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'way',\n",
       " 'i',\n",
       " 'have',\n",
       " 'of',\n",
       " 'driving',\n",
       " 'off',\n",
       " 'the',\n",
       " 'spleen',\n",
       " 'and',\n",
       " 'regulating',\n",
       " 'the',\n",
       " 'circulation',\n",
       " 'whenever',\n",
       " 'i',\n",
       " 'find',\n",
       " 'myself',\n",
       " 'growing',\n",
       " 'grim',\n",
       " 'about',\n",
       " 'the',\n",
       " 'mouth',\n",
       " 'whenever',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'damp',\n",
       " 'drizzly',\n",
       " 'november',\n",
       " 'in',\n",
       " 'my',\n",
       " 'soul',\n",
       " 'whenever',\n",
       " 'i',\n",
       " 'find',\n",
       " 'myself',\n",
       " 'involuntarily',\n",
       " 'pausing',\n",
       " 'before',\n",
       " 'coffin',\n",
       " 'warehouses',\n",
       " 'and',\n",
       " 'bringing',\n",
       " 'up',\n",
       " 'the',\n",
       " 'rear',\n",
       " 'of',\n",
       " 'every',\n",
       " 'funeral',\n",
       " 'i',\n",
       " 'meet',\n",
       " 'and',\n",
       " 'especially',\n",
       " 'whenever',\n",
       " 'my',\n",
       " 'hypos',\n",
       " 'get',\n",
       " 'such',\n",
       " 'an',\n",
       " 'upper',\n",
       " 'hand',\n",
       " 'of',\n",
       " 'me',\n",
       " 'that',\n",
       " 'it',\n",
       " 'requires',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'moral',\n",
       " 'principle',\n",
       " 'to',\n",
       " 'prevent',\n",
       " 'me',\n",
       " 'from',\n",
       " 'deliberately',\n",
       " 'stepping',\n",
       " 'into',\n",
       " 'the',\n",
       " 'street',\n",
       " 'and',\n",
       " 'methodically',\n",
       " 'knocking',\n",
       " 'people',\n",
       " \"'s\",\n",
       " 'hats',\n",
       " 'off',\n",
       " 'then',\n",
       " 'i',\n",
       " 'account',\n",
       " 'it',\n",
       " 'high',\n",
       " 'time',\n",
       " 'to',\n",
       " 'get',\n",
       " 'to',\n",
       " 'sea',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'i',\n",
       " 'can',\n",
       " 'this',\n",
       " 'is',\n",
       " 'my',\n",
       " 'substitute',\n",
       " 'for',\n",
       " 'pistol',\n",
       " 'and',\n",
       " 'ball',\n",
       " 'with',\n",
       " 'a',\n",
       " 'philosophical',\n",
       " 'flourish',\n",
       " 'cato',\n",
       " 'throws',\n",
       " 'himself',\n",
       " 'upon',\n",
       " 'his',\n",
       " 'sword',\n",
       " 'i',\n",
       " 'quietly',\n",
       " 'take',\n",
       " 'to',\n",
       " 'the',\n",
       " 'ship',\n",
       " 'there',\n",
       " 'is',\n",
       " 'nothing',\n",
       " 'surprising',\n",
       " 'in',\n",
       " 'this',\n",
       " 'if',\n",
       " 'they',\n",
       " 'but',\n",
       " 'knew',\n",
       " 'it',\n",
       " 'almost',\n",
       " 'all',\n",
       " 'men',\n",
       " 'in',\n",
       " 'their',\n",
       " 'degree',\n",
       " 'some',\n",
       " 'time',\n",
       " 'or',\n",
       " 'other',\n",
       " 'cherish',\n",
       " 'very',\n",
       " 'nearly',\n",
       " 'the',\n",
       " 'same',\n",
       " 'feelings',\n",
       " 'towards',\n",
       " 'the',\n",
       " 'ocean',\n",
       " 'with',\n",
       " 'me',\n",
       " 'there',\n",
       " 'now',\n",
       " 'is',\n",
       " 'your',\n",
       " 'insular',\n",
       " 'city',\n",
       " 'of',\n",
       " 'the',\n",
       " 'manhattoes',\n",
       " 'belted',\n",
       " 'round',\n",
       " 'by',\n",
       " 'wharves',\n",
       " 'as',\n",
       " 'indian',\n",
       " 'isles',\n",
       " 'by',\n",
       " 'coral',\n",
       " 'reefs',\n",
       " 'commerce',\n",
       " 'surrounds',\n",
       " 'it',\n",
       " 'with',\n",
       " 'her',\n",
       " 'surf',\n",
       " 'right',\n",
       " 'and',\n",
       " 'left',\n",
       " 'the',\n",
       " 'streets',\n",
       " 'take',\n",
       " 'you',\n",
       " 'waterward',\n",
       " 'its',\n",
       " 'extreme',\n",
       " 'downtown',\n",
       " 'is',\n",
       " 'the',\n",
       " 'battery',\n",
       " 'where',\n",
       " 'that',\n",
       " 'noble',\n",
       " 'mole',\n",
       " 'is',\n",
       " 'washed',\n",
       " 'by',\n",
       " 'waves',\n",
       " 'and',\n",
       " 'cooled',\n",
       " 'by',\n",
       " 'breezes',\n",
       " 'which',\n",
       " 'a',\n",
       " 'few',\n",
       " 'hours',\n",
       " 'previous',\n",
       " 'were',\n",
       " 'out',\n",
       " 'of',\n",
       " 'sight',\n",
       " 'of',\n",
       " 'land',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'crowds',\n",
       " 'of',\n",
       " 'water',\n",
       " 'gazers',\n",
       " 'there',\n",
       " 'circumambulate',\n",
       " 'the',\n",
       " 'city',\n",
       " 'of',\n",
       " 'a',\n",
       " 'dreamy',\n",
       " 'sabbath',\n",
       " 'afternoon',\n",
       " 'go',\n",
       " 'from',\n",
       " 'corlears',\n",
       " 'hook',\n",
       " 'to',\n",
       " 'coenties',\n",
       " 'slip',\n",
       " 'and',\n",
       " 'from',\n",
       " 'thence',\n",
       " 'by',\n",
       " 'whitehall',\n",
       " 'northward',\n",
       " 'what',\n",
       " 'do',\n",
       " 'you',\n",
       " 'see?--posted',\n",
       " 'like',\n",
       " 'silent',\n",
       " 'sentinels',\n",
       " 'all',\n",
       " 'around',\n",
       " 'the',\n",
       " 'town',\n",
       " 'stand',\n",
       " 'thousands',\n",
       " 'upon',\n",
       " 'thousands',\n",
       " 'of',\n",
       " 'mortal',\n",
       " 'men',\n",
       " 'fixed',\n",
       " 'in',\n",
       " 'ocean',\n",
       " 'reveries',\n",
       " 'some',\n",
       " 'leaning',\n",
       " 'against',\n",
       " 'the',\n",
       " 'spiles',\n",
       " 'some',\n",
       " 'seated',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'pier',\n",
       " 'heads',\n",
       " 'some',\n",
       " 'looking',\n",
       " 'over',\n",
       " 'the',\n",
       " 'bulwarks',\n",
       " 'of',\n",
       " 'ships',\n",
       " 'from',\n",
       " 'china',\n",
       " 'some',\n",
       " 'high',\n",
       " 'aloft',\n",
       " 'in',\n",
       " 'the',\n",
       " 'rigging',\n",
       " 'as',\n",
       " 'if',\n",
       " 'striving',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'still',\n",
       " 'better',\n",
       " 'seaward',\n",
       " 'peep',\n",
       " 'but',\n",
       " 'these',\n",
       " 'are',\n",
       " 'all',\n",
       " 'landsmen',\n",
       " 'of',\n",
       " 'week',\n",
       " 'days',\n",
       " 'pent',\n",
       " 'up',\n",
       " 'in',\n",
       " 'lath',\n",
       " 'and',\n",
       " 'plaster',\n",
       " 'tied',\n",
       " 'to',\n",
       " 'counters',\n",
       " 'nailed',\n",
       " 'to',\n",
       " 'benches',\n",
       " 'clinched',\n",
       " 'to',\n",
       " 'desks',\n",
       " 'how',\n",
       " 'then',\n",
       " 'is',\n",
       " 'this',\n",
       " 'are',\n",
       " 'the',\n",
       " 'green',\n",
       " 'fields',\n",
       " 'gone',\n",
       " 'what',\n",
       " 'do',\n",
       " 'they',\n",
       " 'here',\n",
       " 'but',\n",
       " 'look',\n",
       " 'here',\n",
       " 'come',\n",
       " 'more',\n",
       " 'crowds',\n",
       " 'pacing',\n",
       " 'straight',\n",
       " 'for',\n",
       " 'the',\n",
       " 'water',\n",
       " 'and',\n",
       " 'seemingly',\n",
       " 'bound',\n",
       " 'for',\n",
       " 'a',\n",
       " 'dive',\n",
       " 'strange',\n",
       " 'nothing',\n",
       " 'will',\n",
       " 'content',\n",
       " 'them',\n",
       " 'but',\n",
       " 'the',\n",
       " 'extremest',\n",
       " 'limit',\n",
       " 'of',\n",
       " 'the',\n",
       " 'land',\n",
       " 'loitering',\n",
       " 'under',\n",
       " 'the',\n",
       " 'shady',\n",
       " 'lee',\n",
       " 'of',\n",
       " 'yonder',\n",
       " 'warehouses',\n",
       " 'will',\n",
       " 'not',\n",
       " 'suffice',\n",
       " 'no',\n",
       " 'they',\n",
       " 'must',\n",
       " 'get',\n",
       " 'just',\n",
       " 'as',\n",
       " 'nigh',\n",
       " 'the',\n",
       " 'water',\n",
       " 'as',\n",
       " 'they',\n",
       " 'possibly',\n",
       " 'can',\n",
       " 'without',\n",
       " 'falling',\n",
       " 'in',\n",
       " 'and',\n",
       " 'there',\n",
       " 'they',\n",
       " 'stand',\n",
       " 'miles',\n",
       " 'of',\n",
       " 'them',\n",
       " 'leagues',\n",
       " 'inlanders',\n",
       " 'all',\n",
       " 'they',\n",
       " 'come',\n",
       " 'from',\n",
       " 'lanes',\n",
       " 'and',\n",
       " 'alleys',\n",
       " 'streets',\n",
       " 'and',\n",
       " 'avenues',\n",
       " 'north',\n",
       " 'east',\n",
       " 'south',\n",
       " 'and',\n",
       " 'west',\n",
       " 'yet',\n",
       " 'here',\n",
       " 'they',\n",
       " 'all',\n",
       " 'unite',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'does',\n",
       " 'the',\n",
       " 'magnetic',\n",
       " 'virtue',\n",
       " 'of',\n",
       " 'the',\n",
       " 'needles',\n",
       " 'of',\n",
       " 'the',\n",
       " 'compasses',\n",
       " 'of',\n",
       " 'all',\n",
       " 'those',\n",
       " 'ships',\n",
       " 'attract',\n",
       " 'them',\n",
       " 'thither',\n",
       " 'once',\n",
       " 'more',\n",
       " 'say',\n",
       " 'you',\n",
       " 'are',\n",
       " 'in',\n",
       " 'the',\n",
       " 'country',\n",
       " 'in',\n",
       " 'some',\n",
       " 'high',\n",
       " 'land',\n",
       " 'of',\n",
       " 'lakes',\n",
       " 'take',\n",
       " 'almost',\n",
       " 'any',\n",
       " 'path',\n",
       " 'you',\n",
       " 'please',\n",
       " 'and',\n",
       " 'ten',\n",
       " 'to',\n",
       " 'one',\n",
       " 'it',\n",
       " 'carries',\n",
       " 'you',\n",
       " 'down',\n",
       " 'in',\n",
       " 'a',\n",
       " 'dale',\n",
       " 'and',\n",
       " 'leaves',\n",
       " 'you',\n",
       " 'there',\n",
       " 'by',\n",
       " 'a',\n",
       " 'pool',\n",
       " 'in',\n",
       " 'the',\n",
       " 'stream',\n",
       " 'there',\n",
       " 'is',\n",
       " 'magic',\n",
       " 'in',\n",
       " 'it',\n",
       " 'let',\n",
       " 'the',\n",
       " 'most',\n",
       " 'absent',\n",
       " 'minded',\n",
       " 'of',\n",
       " 'men',\n",
       " 'be',\n",
       " 'plunged',\n",
       " 'in',\n",
       " 'his',\n",
       " 'deepest',\n",
       " 'reveries',\n",
       " 'stand',\n",
       " 'that',\n",
       " 'man',\n",
       " 'on',\n",
       " 'his',\n",
       " 'legs',\n",
       " 'set',\n",
       " 'his',\n",
       " 'feet',\n",
       " 'a',\n",
       " 'going',\n",
       " 'and',\n",
       " 'he',\n",
       " 'will',\n",
       " 'infallibly',\n",
       " 'lead',\n",
       " 'you',\n",
       " 'to',\n",
       " 'water',\n",
       " 'if',\n",
       " 'water',\n",
       " 'there',\n",
       " 'be',\n",
       " 'in',\n",
       " 'all',\n",
       " 'that',\n",
       " 'region',\n",
       " 'should',\n",
       " 'you',\n",
       " 'ever',\n",
       " 'be',\n",
       " 'athirst',\n",
       " 'in',\n",
       " 'the',\n",
       " 'great',\n",
       " 'american',\n",
       " 'desert',\n",
       " 'try',\n",
       " 'this',\n",
       " 'experiment',\n",
       " 'if',\n",
       " 'your',\n",
       " 'caravan',\n",
       " 'happen',\n",
       " 'to',\n",
       " 'be',\n",
       " 'supplied',\n",
       " 'with',\n",
       " 'a',\n",
       " 'metaphysical',\n",
       " 'professor',\n",
       " 'yes',\n",
       " 'as',\n",
       " 'every',\n",
       " 'one',\n",
       " 'knows',\n",
       " 'meditation',\n",
       " 'and',\n",
       " 'water',\n",
       " 'are',\n",
       " 'wedded',\n",
       " 'for',\n",
       " 'ever',\n",
       " 'but',\n",
       " 'here',\n",
       " 'is',\n",
       " 'an',\n",
       " 'artist',\n",
       " 'he',\n",
       " 'desires',\n",
       " 'to',\n",
       " 'paint',\n",
       " 'you',\n",
       " 'the',\n",
       " 'dreamiest',\n",
       " 'shadiest',\n",
       " 'quietest',\n",
       " 'most',\n",
       " 'enchanting',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'romantic',\n",
       " 'landscape',\n",
       " 'in',\n",
       " 'all',\n",
       " 'the',\n",
       " 'valley',\n",
       " 'of',\n",
       " 'the',\n",
       " 'saco',\n",
       " 'what',\n",
       " 'is',\n",
       " 'the',\n",
       " 'chief',\n",
       " 'element',\n",
       " 'he',\n",
       " 'employs',\n",
       " 'there',\n",
       " 'stand',\n",
       " 'his',\n",
       " 'trees',\n",
       " 'each',\n",
       " 'with',\n",
       " 'a',\n",
       " 'hollow',\n",
       " 'trunk',\n",
       " 'as',\n",
       " 'if',\n",
       " 'a',\n",
       " 'hermit',\n",
       " 'and',\n",
       " 'a',\n",
       " 'crucifix',\n",
       " 'were',\n",
       " 'within',\n",
       " 'and',\n",
       " 'here',\n",
       " 'sleeps',\n",
       " 'his',\n",
       " 'meadow',\n",
       " 'and',\n",
       " 'there',\n",
       " 'sleep',\n",
       " 'his',\n",
       " 'cattle',\n",
       " 'and',\n",
       " 'up',\n",
       " 'from',\n",
       " 'yonder',\n",
       " 'cottage',\n",
       " 'goes',\n",
       " 'a',\n",
       " 'sleepy',\n",
       " 'smoke',\n",
       " 'deep',\n",
       " 'into',\n",
       " 'distant',\n",
       " 'woodlands',\n",
       " 'winds',\n",
       " 'a',\n",
       " 'mazy',\n",
       " 'way',\n",
       " 'reaching',\n",
       " 'to',\n",
       " 'overlapping',\n",
       " 'spurs',\n",
       " 'of',\n",
       " 'mountains',\n",
       " 'bathed',\n",
       " 'in',\n",
       " 'their',\n",
       " 'hill',\n",
       " 'side',\n",
       " 'blue',\n",
       " 'but',\n",
       " 'though',\n",
       " 'the',\n",
       " 'picture',\n",
       " 'lies',\n",
       " 'thus',\n",
       " 'tranced',\n",
       " 'and',\n",
       " 'though',\n",
       " 'this',\n",
       " 'pine',\n",
       " 'tree',\n",
       " 'shakes',\n",
       " 'down',\n",
       " 'its',\n",
       " 'sighs',\n",
       " 'like',\n",
       " 'leaves',\n",
       " 'upon',\n",
       " 'this',\n",
       " 'shepherd',\n",
       " \"'s\",\n",
       " 'head',\n",
       " 'yet',\n",
       " 'all',\n",
       " 'were',\n",
       " 'vain',\n",
       " 'unless',\n",
       " 'the',\n",
       " 'shepherd',\n",
       " \"'s\",\n",
       " 'eye',\n",
       " 'were',\n",
       " 'fixed',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'magic',\n",
       " 'stream',\n",
       " 'before',\n",
       " 'him',\n",
       " 'go',\n",
       " 'visit',\n",
       " 'the',\n",
       " 'prairies',\n",
       " 'in',\n",
       " 'june',\n",
       " 'when',\n",
       " 'for',\n",
       " 'scores',\n",
       " 'on',\n",
       " 'scores',\n",
       " 'of',\n",
       " 'miles',\n",
       " 'you',\n",
       " 'wade',\n",
       " 'knee',\n",
       " 'deep',\n",
       " 'among',\n",
       " 'tiger',\n",
       " 'lilies',\n",
       " 'what',\n",
       " 'is',\n",
       " 'the',\n",
       " 'one',\n",
       " 'charm',\n",
       " 'wanting?--water',\n",
       " 'there',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'drop',\n",
       " 'of',\n",
       " 'water',\n",
       " 'there',\n",
       " 'were',\n",
       " 'niagara',\n",
       " 'but',\n",
       " 'a',\n",
       " 'cataract',\n",
       " 'of',\n",
       " 'sand',\n",
       " 'would',\n",
       " 'you',\n",
       " 'travel',\n",
       " 'your',\n",
       " 'thousand',\n",
       " 'miles',\n",
       " 'to',\n",
       " 'see',\n",
       " 'it',\n",
       " 'why',\n",
       " 'did',\n",
       " 'the',\n",
       " 'poor',\n",
       " 'poet',\n",
       " 'of',\n",
       " 'tennessee',\n",
       " 'upon',\n",
       " 'suddenly',\n",
       " 'receiving',\n",
       " 'two',\n",
       " 'handfuls',\n",
       " 'of',\n",
       " 'silver',\n",
       " 'deliberate',\n",
       " 'whether',\n",
       " 'to',\n",
       " 'buy',\n",
       " 'him',\n",
       " 'a',\n",
       " 'coat',\n",
       " 'which',\n",
       " 'he',\n",
       " 'sadly',\n",
       " 'needed',\n",
       " 'or',\n",
       " 'invest',\n",
       " 'his',\n",
       " 'money',\n",
       " 'in',\n",
       " 'a',\n",
       " 'pedestrian',\n",
       " 'trip',\n",
       " 'to',\n",
       " 'rockaway',\n",
       " 'beach',\n",
       " 'why',\n",
       " 'is',\n",
       " 'almost',\n",
       " 'every',\n",
       " 'robust',\n",
       " 'healthy',\n",
       " 'boy',\n",
       " 'with',\n",
       " 'a',\n",
       " 'robust',\n",
       " 'healthy',\n",
       " 'soul',\n",
       " 'in',\n",
       " 'him',\n",
       " 'at',\n",
       " 'some',\n",
       " 'time',\n",
       " 'or',\n",
       " 'other',\n",
       " 'crazy',\n",
       " 'to',\n",
       " 'go',\n",
       " 'to',\n",
       " 'sea',\n",
       " 'why',\n",
       " 'upon',\n",
       " 'your',\n",
       " 'first',\n",
       " 'voyage',\n",
       " 'as',\n",
       " 'a',\n",
       " 'passenger',\n",
       " 'did',\n",
       " 'you',\n",
       " 'yourself',\n",
       " 'feel',\n",
       " 'such',\n",
       " 'a',\n",
       " 'mystical',\n",
       " 'vibration',\n",
       " 'when',\n",
       " 'first',\n",
       " 'told',\n",
       " 'that',\n",
       " 'you',\n",
       " 'and',\n",
       " 'your',\n",
       " 'ship',\n",
       " 'were',\n",
       " 'now',\n",
       " 'out',\n",
       " 'of',\n",
       " 'sight',\n",
       " 'of',\n",
       " 'land',\n",
       " 'why',\n",
       " 'did',\n",
       " 'the',\n",
       " 'old',\n",
       " 'persians',\n",
       " 'hold',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'holy',\n",
       " 'why',\n",
       " 'did',\n",
       " 'the',\n",
       " 'greeks',\n",
       " 'give',\n",
       " 'it',\n",
       " 'a',\n",
       " 'separate',\n",
       " 'deity',\n",
       " 'and',\n",
       " 'own',\n",
       " 'brother',\n",
       " 'of',\n",
       " 'jove',\n",
       " 'surely',\n",
       " 'all',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'without',\n",
       " 'meaning',\n",
       " 'and',\n",
       " 'still',\n",
       " 'deeper',\n",
       " 'the',\n",
       " 'meaning',\n",
       " 'of',\n",
       " 'that',\n",
       " 'story',\n",
       " 'of',\n",
       " 'narcissus',\n",
       " 'who',\n",
       " 'because',\n",
       " 'he',\n",
       " 'could',\n",
       " 'not',\n",
       " 'grasp',\n",
       " 'the',\n",
       " 'tormenting',\n",
       " 'mild',\n",
       " 'image',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'in',\n",
       " 'the',\n",
       " 'fountain',\n",
       " 'plunged',\n",
       " 'into',\n",
       " 'it',\n",
       " 'and',\n",
       " 'was',\n",
       " 'drowned',\n",
       " 'but',\n",
       " 'that',\n",
       " 'same',\n",
       " 'image',\n",
       " 'we',\n",
       " 'ourselves',\n",
       " 'see',\n",
       " 'in',\n",
       " 'all',\n",
       " 'rivers',\n",
       " 'and',\n",
       " 'oceans',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'image',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ungraspable',\n",
       " 'phantom',\n",
       " 'of',\n",
       " 'life',\n",
       " 'and',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'key',\n",
       " 'to',\n",
       " 'it',\n",
       " 'all',\n",
       " 'now',\n",
       " 'when',\n",
       " 'i',\n",
       " 'say',\n",
       " 'that',\n",
       " 'i',\n",
       " 'am',\n",
       " 'in',\n",
       " 'the',\n",
       " 'habit',\n",
       " 'of',\n",
       " 'going',\n",
       " 'to',\n",
       " 'sea',\n",
       " 'whenever',\n",
       " 'i',\n",
       " 'begin',\n",
       " 'to',\n",
       " 'grow',\n",
       " 'hazy',\n",
       " 'about',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = seperate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214712"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 25 + 1\n",
    "\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len,len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "    \n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chapter 1 loomings call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 loomings call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 : chapter\n",
      "9447 : 1\n",
      "17527 : loomings\n",
      "402 : call\n",
      "42 : me\n",
      "1043 : ishmael\n",
      "43 : some\n",
      "247 : years\n",
      "659 : ago\n",
      "140 : never\n",
      "296 : mind\n",
      "116 : how\n",
      "82 : long\n",
      "787 : precisely\n",
      "347 : having\n",
      "113 : little\n",
      "36 : or\n",
      "50 : no\n",
      "1788 : money\n",
      "6 : in\n",
      "49 : my\n",
      "3028 : purse\n",
      "3 : and\n",
      "218 : nothing\n",
      "442 : particular\n",
      "5 : to\n"
     ]
    }
   ],
   "source": [
    "for i in sequences[0]:\n",
    "    print(f\"{i} : {tokenizer.index_word[i]}\")\n",
    "    \n",
    "    #tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17527"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  158,  9447, 17527, ...,   218,   442,     5],\n",
       "       [ 9447, 17527,   402, ...,   442,     5,  1165],\n",
       "       [17527,   402,    42, ...,     5,  1165,    42],\n",
       "       ...,\n",
       "       [  240,   937,   351, ...,  1419,  1313,    74],\n",
       "       [  937,   351,  1418, ...,  1313,    74,   219],\n",
       "       [  351,  1418,     3, ...,    74,   219,   222]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   5, 1165,   42, ...,   74,  219,  222])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = sequences[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y,num_classes=vocabulary_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = X.shape[1]\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214686, 25)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, seq_len, input_length=seq_len))\n",
    "    model.add(LSTM(100,return_sequences=True))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 25)            438200    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25, 100)           50400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17528)             1770328   \n",
      "=================================================================\n",
      "Total params: 2,294,228\n",
      "Trainable params: 2,294,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "214686/214686 [==============================] - 317s 1ms/step - loss: 7.0048 - accuracy: 0.0686\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 2/350\n",
      "214686/214686 [==============================] - 349s 2ms/step - loss: 6.6093 - accuracy: 0.0839\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 3/350\n",
      "214686/214686 [==============================] - 342s 2ms/step - loss: 6.3759 - accuracy: 0.0944\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 4/350\n",
      "214686/214686 [==============================] - 386s 2ms/step - loss: 6.2199 - accuracy: 0.1051\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 5/350\n",
      "214686/214686 [==============================] - 356s 2ms/step - loss: 6.0953 - accuracy: 0.1118\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 6/350\n",
      "214686/214686 [==============================] - 350s 2ms/step - loss: 5.9877 - accuracy: 0.1153\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 7/350\n",
      "214686/214686 [==============================] - 346s 2ms/step - loss: 5.8917 - accuracy: 0.1182\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 8/350\n",
      "214686/214686 [==============================] - 337s 2ms/step - loss: 5.8032 - accuracy: 0.1205\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 9/350\n",
      "214686/214686 [==============================] - 333s 2ms/step - loss: 5.7184 - accuracy: 0.1233\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 10/350\n",
      "214686/214686 [==============================] - 352s 2ms/step - loss: 5.6396 - accuracy: 0.1263\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 11/350\n",
      "214686/214686 [==============================] - 386s 2ms/step - loss: 5.5678 - accuracy: 0.1286\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 12/350\n",
      "214686/214686 [==============================] - 542s 3ms/step - loss: 5.5016 - accuracy: 0.1297\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 13/350\n",
      "214686/214686 [==============================] - 447s 2ms/step - loss: 5.4394 - accuracy: 0.1315\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 14/350\n",
      "214686/214686 [==============================] - 346s 2ms/step - loss: 5.3801 - accuracy: 0.13351s - loss: 5.3798 - ac\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 15/350\n",
      "214686/214686 [==============================] - 320s 1ms/step - loss: 5.3244 - accuracy: 0.1350\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 16/350\n",
      "214686/214686 [==============================] - 333s 2ms/step - loss: 5.2694 - accuracy: 0.1370\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 17/350\n",
      "214686/214686 [==============================] - 332s 2ms/step - loss: 5.2170 - accuracy: 0.1384\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 18/350\n",
      "214686/214686 [==============================] - 339s 2ms/step - loss: 5.1661 - accuracy: 0.1405\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 19/350\n",
      "214686/214686 [==============================] - 341s 2ms/step - loss: 5.1161 - accuracy: 0.1421\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 20/350\n",
      "214686/214686 [==============================] - 348s 2ms/step - loss: 5.0693 - accuracy: 0.1448\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 21/350\n",
      "214686/214686 [==============================] - 369s 2ms/step - loss: 5.0252 - accuracy: 0.1469\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 22/350\n",
      "214686/214686 [==============================] - 348s 2ms/step - loss: 4.9824 - accuracy: 0.1493\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 23/350\n",
      "214686/214686 [==============================] - 348s 2ms/step - loss: 4.9429 - accuracy: 0.1512\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 24/350\n",
      "214686/214686 [==============================] - 359s 2ms/step - loss: 4.9032 - accuracy: 0.1535\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 25/350\n",
      "214686/214686 [==============================] - 331s 2ms/step - loss: 4.8667 - accuracy: 0.1558\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 26/350\n",
      "214686/214686 [==============================] - 341s 2ms/step - loss: 4.8316 - accuracy: 0.1576\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 27/350\n",
      "214686/214686 [==============================] - 343s 2ms/step - loss: 4.7956 - accuracy: 0.1603\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 28/350\n",
      "214686/214686 [==============================] - 335s 2ms/step - loss: 4.7626 - accuracy: 0.1622\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 29/350\n",
      "214686/214686 [==============================] - 343s 2ms/step - loss: 4.7312 - accuracy: 0.1645\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 30/350\n",
      "214686/214686 [==============================] - 344s 2ms/step - loss: 4.7006 - accuracy: 0.1671\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 31/350\n",
      "214686/214686 [==============================] - 344s 2ms/step - loss: 4.6684 - accuracy: 0.1689\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 32/350\n",
      "214686/214686 [==============================] - 352s 2ms/step - loss: 4.6402 - accuracy: 0.1718\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 33/350\n",
      "214686/214686 [==============================] - 393s 2ms/step - loss: 4.6139 - accuracy: 0.1732\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 34/350\n",
      "214686/214686 [==============================] - 486s 2ms/step - loss: 4.5842 - accuracy: 0.1761\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 35/350\n",
      "214686/214686 [==============================] - 10248s 48ms/step - loss: 4.5575 - accuracy: 0.1787\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 36/350\n",
      "214686/214686 [==============================] - 470s 2ms/step - loss: 4.5320 - accuracy: 0.1802\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 37/350\n",
      "214686/214686 [==============================] - 1292s 6ms/step - loss: 4.5066 - accuracy: 0.1825\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 38/350\n",
      "214686/214686 [==============================] - 669s 3ms/step - loss: 4.4815 - accuracy: 0.1845\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 39/350\n",
      "214686/214686 [==============================] - 484s 2ms/step - loss: 4.4576 - accuracy: 0.1865\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 40/350\n",
      "214686/214686 [==============================] - 535s 2ms/step - loss: 4.4325 - accuracy: 0.1899\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 41/350\n",
      "214686/214686 [==============================] - 369s 2ms/step - loss: 4.4069 - accuracy: 0.1921\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 42/350\n",
      "214686/214686 [==============================] - 349s 2ms/step - loss: 4.3860 - accuracy: 0.1941\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 43/350\n",
      "214686/214686 [==============================] - 376s 2ms/step - loss: 4.3631 - accuracy: 0.1959\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 44/350\n",
      "214686/214686 [==============================] - 375s 2ms/step - loss: 4.3386 - accuracy: 0.1985\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 45/350\n",
      "214686/214686 [==============================] - 385s 2ms/step - loss: 4.3169 - accuracy: 0.2009\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 46/350\n",
      "214686/214686 [==============================] - 366s 2ms/step - loss: 4.2954 - accuracy: 0.2034\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 47/350\n",
      "214686/214686 [==============================] - 385s 2ms/step - loss: 4.2728 - accuracy: 0.2048\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 48/350\n",
      "214686/214686 [==============================] - 410s 2ms/step - loss: 4.2518 - accuracy: 0.2069\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 49/350\n",
      "214686/214686 [==============================] - 415s 2ms/step - loss: 4.2290 - accuracy: 0.2099\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 50/350\n",
      "214686/214686 [==============================] - 551s 3ms/step - loss: 4.2105 - accuracy: 0.2117\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 51/350\n",
      "214686/214686 [==============================] - 563s 3ms/step - loss: 4.1905 - accuracy: 0.2146\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 52/350\n",
      "214686/214686 [==============================] - 502s 2ms/step - loss: 4.1702 - accuracy: 0.2159\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 53/350\n",
      "214686/214686 [==============================] - 454s 2ms/step - loss: 4.1511 - accuracy: 0.2185\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 54/350\n",
      "214686/214686 [==============================] - 374s 2ms/step - loss: 4.1323 - accuracy: 0.2211\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 55/350\n",
      "214686/214686 [==============================] - 383s 2ms/step - loss: 4.1138 - accuracy: 0.2234\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 56/350\n",
      "214686/214686 [==============================] - 425s 2ms/step - loss: 4.0954 - accuracy: 0.2250\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 57/350\n",
      "214686/214686 [==============================] - 406s 2ms/step - loss: 4.0765 - accuracy: 0.2273\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 58/350\n",
      "214686/214686 [==============================] - 426s 2ms/step - loss: 4.0589 - accuracy: 0.2290\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 59/350\n",
      "214686/214686 [==============================] - 395s 2ms/step - loss: 4.0424 - accuracy: 0.2307\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 60/350\n",
      "214686/214686 [==============================] - 421s 2ms/step - loss: 4.0257 - accuracy: 0.2335\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 61/350\n",
      "214686/214686 [==============================] - 411s 2ms/step - loss: 4.0058 - accuracy: 0.2357\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 62/350\n",
      "214686/214686 [==============================] - 414s 2ms/step - loss: 3.9901 - accuracy: 0.2380\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 63/350\n",
      "214686/214686 [==============================] - 410s 2ms/step - loss: 3.9776 - accuracy: 0.2387\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 64/350\n",
      "214686/214686 [==============================] - 430s 2ms/step - loss: 3.9597 - accuracy: 0.2421\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 65/350\n",
      "214686/214686 [==============================] - 418s 2ms/step - loss: 3.9468 - accuracy: 0.2425\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 66/350\n",
      "214686/214686 [==============================] - 424s 2ms/step - loss: 3.9311 - accuracy: 0.2448\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 67/350\n",
      "214686/214686 [==============================] - 421s 2ms/step - loss: 3.9127 - accuracy: 0.2464\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 68/350\n",
      "214686/214686 [==============================] - 378s 2ms/step - loss: 3.8998 - accuracy: 0.2480\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 69/350\n",
      "214686/214686 [==============================] - 414s 2ms/step - loss: 3.8856 - accuracy: 0.2502\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 70/350\n",
      "214686/214686 [==============================] - 414s 2ms/step - loss: 3.8715 - accuracy: 0.2523\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 71/350\n",
      "214686/214686 [==============================] - 413s 2ms/step - loss: 3.8582 - accuracy: 0.2536\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 72/350\n",
      "214686/214686 [==============================] - 432s 2ms/step - loss: 3.8460 - accuracy: 0.2554\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 73/350\n",
      "126208/214686 [================>.............] - ETA: 1:28:17 - loss: 3.7863 - accuracy: 0.2644"
     ]
    }
   ],
   "source": [
    "model.fit(X,y,batch_size=128, epochs=350, verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('moby_dick.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tokenizer,open('my_tokenizer','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    \n",
    "    output_text = []\n",
    "    \n",
    "    input_text = seed_text\n",
    "    \n",
    "    for i in range(num_gen_words):\n",
    "        \n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        pad_encoded = pad_sequences([encoded_text],maxlen=seq_len, truncating='pre')\n",
    "        \n",
    "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
    "        \n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        \n",
    "        input_text += ' '+pred_word\n",
    "        \n",
    "        output_text.append(pred_word)\n",
    "    \n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(101)\n",
    "random_pick = random.randint(0,len(text_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed_text = text_sequences[random_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = ' '.join(random_seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(model, tokenizer, seq_len, seed_text=seed_text, num_gen_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
